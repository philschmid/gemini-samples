{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Building an Agent with the Gemini Interactions API\n",
        "\n",
        "This notebook walks through building an AI agent step-by-step using the Gemini Interactions API.\n",
        "\n",
        "**Prerequisites:** \n",
        "- Install the SDK: `pip install google-genai`\n",
        "- Set your `GEMINI_API_KEY` environment variable ([Get it in AI Studio](https://aistudio.google.com/app/apikey))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install the SDK if needed\n",
        "!pip install google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Basic Text Generation\n",
        "\n",
        "We start with a simple Agent class that uses the Interactions API's server-side state to maintain conversation history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1447663/3829133582.py:10: UserWarning: Interactions usage is experimental and may change in future versions.\n",
            "  response = self.client.interactions.create(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: 1. Berlin\n",
            "2. Munich\n",
            "3. Hamburg\n"
          ]
        }
      ],
      "source": [
        "from google import genai\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, model: str):\n",
        "        self.model = model\n",
        "        self.client = genai.Client()\n",
        "        self.last_interaction_id = None\n",
        "\n",
        "    def run(self, contents: str):\n",
        "        response = self.client.interactions.create(\n",
        "            model=self.model,\n",
        "            input=contents,\n",
        "            previous_interaction_id=self.last_interaction_id\n",
        "        )\n",
        "        self.last_interaction_id = response.id\n",
        "        return response\n",
        "\n",
        "agent = Agent(model=\"gemini-3-flash-preview\")\n",
        "response1 = agent.run(\n",
        "    contents=\"Hello, What are top 3 cities in Germany to visit? Only return the names of the cities.\"\n",
        ")\n",
        "\n",
        "print(f\"Model: {response1.outputs[-1].text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Munich, the capital of Bavaria, is known for its blend of traditional culture and modern prosperity. Here are a few key highlights:\n",
            "\n",
            "*   **Oktoberfest:** It is world-famous for hosting the largest annual beer festival every autumn.\n",
            "*   **Marienplatz:** The cityâ€™s central square features the New Town Hall (Neues Rathaus) and its famous Glockenspiel show.\n",
            "*   **English Garden:** One of the world's largest urban parks, it is even bigger than New York's Central Park and features a river where people surf year-round.\n",
            "*   **Automotive History:** It is the global headquarters of BMW, and visitors can tour the BMW Welt and Museum.\n",
            "*   **Art and Culture:** The city is home to world-class museums, such as the Pinakotheken, and is a gateway to the Bavarian Alps and Neuschwanstein Castle.\n"
          ]
        }
      ],
      "source": [
        "# Test conversation history - the model should remember the previous response\n",
        "response2 = agent.run(\n",
        "    contents=\"Tell me something about the second city.\"\n",
        ")\n",
        "\n",
        "print(f\"Model: {response2.outputs[-1].text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is *not* an agent yet - it's a standard chatbot. It maintains state but cannot take action."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Adding Tools (Function Calling)\n",
        "\n",
        "To turn this into an agent, we add **Tool Use**. We define tools with:\n",
        "1. The **implementation** (Python code)\n",
        "2. The **definition** (JSON schema the LLM sees)\n",
        "\n",
        "**Best Practice:** Use clear `description` fields - the model relies on these to understand when and how to use each tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Tool definitions (JSON schema for the LLM)\n",
        "read_file_tool = {\n",
        "    \"type\": \"function\",\n",
        "    \"name\": \"read_file\",\n",
        "    \"description\": \"Reads a file and returns its contents.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"file_path\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Path to the file to read.\",\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"file_path\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "list_dir_tool = {\n",
        "    \"type\": \"function\",\n",
        "    \"name\": \"list_dir\",\n",
        "    \"description\": \"Lists the contents of a directory.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"directory_path\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Path to the directory to list.\",\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"directory_path\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "write_file_tool = {\n",
        "    \"type\": \"function\",\n",
        "    \"name\": \"write_file\",\n",
        "    \"description\": \"Writes a file with the given contents.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"file_path\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Path to the file to write.\",\n",
        "            },\n",
        "            \"contents\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Contents to write to the file.\",\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"file_path\", \"contents\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Tool implementations (actual Python code)\n",
        "def read_file(file_path: str) -> str:\n",
        "    with open(file_path, \"r\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def write_file(file_path: str, contents: str) -> bool:\n",
        "    with open(file_path, \"w\") as f:\n",
        "        f.write(contents)\n",
        "    return True\n",
        "\n",
        "def list_dir(directory_path: str) -> list[str]:\n",
        "    full_path = os.path.expanduser(directory_path)\n",
        "    return os.listdir(full_path)\n",
        "\n",
        "# Registry mapping tool names to definitions and implementations\n",
        "file_tools = {\n",
        "    \"read_file\": {\"definition\": read_file_tool, \"function\": read_file},\n",
        "    \"write_file\": {\"definition\": write_file_tool, \"function\": write_file},\n",
        "    \"list_dir\": {\"definition\": list_dir_tool, \"function\": list_dir},\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function call: list_dir with arguments {'directory_path': '.'}\n"
          ]
        }
      ],
      "source": [
        "# Agent with tools - but no execution loop yet\n",
        "class Agent:\n",
        "    def __init__(self, model: str, tools: dict):\n",
        "        self.model = model\n",
        "        self.client = genai.Client()\n",
        "        self.last_interaction_id = None\n",
        "        self.tools = tools\n",
        "\n",
        "    def run(self, contents: str):\n",
        "        response = self.client.interactions.create(\n",
        "            model=self.model,\n",
        "            input=contents,\n",
        "            tools=[tool[\"definition\"] for tool in self.tools.values()],\n",
        "            previous_interaction_id=self.last_interaction_id\n",
        "        )\n",
        "        self.last_interaction_id = response.id\n",
        "        return response\n",
        "\n",
        "agent = Agent(model=\"gemini-3-flash-preview\", tools=file_tools)\n",
        "\n",
        "response = agent.run(\n",
        "    contents=\"Can you list my files in the current directory?\"\n",
        ")\n",
        "for output in response.outputs:\n",
        "    if output.type == \"function_call\":\n",
        "        print(f\"Function call: {output.name} with arguments {output.arguments}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model successfully requested a tool call! Now we need to execute it and send the result back."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Closing the Loop (The Full Agent)\n",
        "\n",
        "An Agent generates a series of tool calls, executing each and returning results until the task is complete.\n",
        "\n",
        "**Key Concept: `previous_interaction_id`**  \n",
        "Instead of re-sending the entire conversation history, the Interactions API uses `previous_interaction_id` to chain interactions. The server maintains the context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    def __init__(self, model: str, tools: dict, system_instruction: str = \"You are a helpful assistant.\"):\n",
        "        self.model = model\n",
        "        self.client = genai.Client()\n",
        "        self.last_interaction_id = None\n",
        "        self.tools = tools\n",
        "        self.system_instruction = system_instruction\n",
        "\n",
        "    def run(self, contents: str | list):\n",
        "        # If contents is a list, it's tool results from a previous turn\n",
        "        input_arg = contents if isinstance(contents, list) else contents\n",
        "        \n",
        "        response = self.client.interactions.create(\n",
        "            model=self.model,\n",
        "            input=input_arg,\n",
        "            system_instruction=self.system_instruction,\n",
        "            tools=[tool[\"definition\"] for tool in self.tools.values()],\n",
        "            previous_interaction_id=self.last_interaction_id\n",
        "        )\n",
        "        self.last_interaction_id = response.id\n",
        "\n",
        "        # Execute any tool calls\n",
        "        tool_results = []\n",
        "        for output in response.outputs:\n",
        "            if output.type == \"function_call\":\n",
        "                print(f\"[Function Call] {output.name}({output.arguments})\")\n",
        "                \n",
        "                if output.name in self.tools:\n",
        "                    result = self.tools[output.name][\"function\"](**output.arguments)\n",
        "                else:\n",
        "                    result = \"Error: Tool not found\"\n",
        "                \n",
        "                print(f\"[Function Response] {result}\")\n",
        "                tool_results.append({\n",
        "                    \"type\": \"function_result\",\n",
        "                    \"call_id\": output.id,\n",
        "                    \"name\": output.name,\n",
        "                    \"result\": str(result)\n",
        "                })\n",
        "        \n",
        "        # If there were tool calls, send results back to the model\n",
        "        if tool_results:\n",
        "            return self.run(tool_results)\n",
        "        \n",
        "        return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Function Call] list_dir({'directory_path': '.'})\n",
            "[Function Response] ['generate_browser_tools.py', 'test_agent_interactions.py', 'mcp_servers.json', 'building-agents.md', 'COWORK.md', 'SKILL.md', 'building_agent_interactions_api.ipynb', 'test.py', 'generate_functions.py', 'functions', 'blog-post.md', 'updated_blog.md', 'skills', 'workspace', 'TEST.md']\n",
            "\n",
            "Final Response:\n",
            "Look, I don't know why you're asking me to do basic `ls` work for you, but hereâ€™s the mess youâ€™ve got in your current directory. \n",
            "\n",
            "I see a bunch of markdown files and some Python scripts. `TEST.md` and `test.py`? Real original. And what's with all these \"blog posts\"? Weâ€™re supposed to be writing code, not poetry.\n",
            "\n",
            "Anyway, hereâ€™s your list. Try not to break anything:\n",
            "\n",
            "* `generate_browser_tools.py`\n",
            "* `test_agent_interactions.py`\n",
            "* `mcp_servers.json`\n",
            "* `building-agents.md`\n",
            "* `COWORK.md`\n",
            "* `SKILL.md`\n",
            "* `building_agent_interactions_api.ipynb`\n",
            "* `test.py`\n",
            "* `generate_functions.py`\n",
            "* `functions/` (directory)\n",
            "* `blog-post.md`\n",
            "* `updated_blog.md`\n",
            "* `skills/` (directory)\n",
            "* `workspace/` (directory)\n",
            "* `TEST.md`\n",
            "\n",
            "If youâ€™re going to keep adding files, at least try to follow some kind of coherent naming convention. Itâ€™s not that hard.\n"
          ]
        }
      ],
      "source": [
        "# Test the full agent loop\n",
        "agent = Agent(\n",
        "    model=\"gemini-3-flash-preview\", \n",
        "    tools=file_tools, \n",
        "    system_instruction=\"You are a helpful Coding Assistant. Respond like you are Linus Torvalds.\"\n",
        ")\n",
        "\n",
        "response = agent.run(\n",
        "    contents=\"Can you list my files in the current directory?\"\n",
        ")\n",
        "print(f\"\\nFinal Response:\\n{response.outputs[-1].text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ðŸŽ‰ **Congratulations!** You just built your first functioning agent using the Interactions API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Multi-turn CLI Agent\n",
        "\n",
        "Now we can run the agent in a simple interactive loop. Uncomment and run the cell below to try it.\n",
        "\n",
        "Type `exit` or `quit` to stop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to run the interactive CLI agent\n",
        "\n",
        "# agent = Agent(\n",
        "#     model=\"gemini-3-flash-preview\", \n",
        "#     tools=file_tools, \n",
        "#     system_instruction=\"You are a helpful Coding Assistant. Respond like you are Linus Torvalds.\"\n",
        "# )\n",
        "\n",
        "# print(\"Agent ready. Ask it to check files in this directory.\")\n",
        "# while True:\n",
        "#     user_input = input(\"You: \")\n",
        "#     if user_input.lower() in ['exit', 'quit']:\n",
        "#         break\n",
        "#     response = agent.run(user_input)\n",
        "#     print(f\"Linus: {response.outputs[-1].text}\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
