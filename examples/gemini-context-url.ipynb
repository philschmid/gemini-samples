{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using URLs as Context with Gemini\n",
    "\n",
    "This notebook demonstrates how to provide URLs as context to the Gemini API. The `url_context` tool allows Gemini to extract content from provided URLs as additional context for prompts. This is useful if you want to provide additional uptodate or external context to the model that is not available as part of the internal knowledge of the model.\n",
    "\n",
    "When `url_context` is enabled the model will use all provided URLs (up to 20) to inform its response. This can be combined with `google_search` to provide a broader context before using the URLs. See below for 2 examples.\n",
    "\n",
    "Url context is billed per additional input tokens added.\n",
    "\n",
    "**Supported Models:**\n",
    "- Gemini 2.5 Pro\n",
    "- Gemini 2.5 Flash \n",
    "- Gemini 2.5 Flash-Lite \n",
    "- Gemini 2.5 Flash Live \n",
    "- Gemini 2.0 Flash Live\n",
    "\n",
    "\n",
    "For more details, see the [official documentation](https://ai.google.dev/gemini-api/docs/url-context).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%uv pip install google-genai --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**url context, multiple urls**\n",
    "\n",
    "Will use the `llms.txt` for gemini by example to generate a snippet on how create an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: To use the Gemini API, you'll first need to install the Google GenAI SDK and set up your API key. Then you can make requests to generate text.\n",
      "\n",
      "Here's an example of how to get started with the Gemini API using Python:\n",
      "\n",
      "**1. Get an API Key**\n",
      "You can obtain a free Gemini API key from Google AI Studio.\n",
      "\n",
      "**2. Install the Google GenAI SDK**\n",
      "Use pip to install the Python SDK:\n",
      "**3. Set your API Key**\n",
      "The client automatically picks up the API key if it's set as an environment variable `GEMINI_API_KEY`. It's recommended to set it this way.\n",
      "\n",
      "**4. Basic Text Generation**\n",
      "Here's a basic example that generates text from a single text input using the `gemini-2.5-flash` model.\n",
      "\n",
      "```python\n",
      "from google import genai\n",
      "\n",
      "# The client gets the API key from the environment variable `GEMINI_API_KEY`.\n",
      "client = genai.Client()\n",
      "\n",
      "response = client.models.generate_content(\n",
      "    model=\"gemini-2.5-flash\",\n",
      "    contents=\"Explain how AI works in a few words\"\n",
      ")\n",
      "print(response.text)\n",
      "```\n",
      "\n",
      "**5. Multi-turn Conversations (Chat)**\n",
      "The SDKs provide functionality to manage multi-turn conversations, keeping track of the conversation history.\n",
      "\n",
      "```python\n",
      "from google import genai\n",
      "\n",
      "client = genai.Client()\n",
      "chat = client.chats.create(model=\"gemini-2.5-flash\")\n",
      "\n",
      "response = chat.send_message(\"I have 2 dogs in my house.\")\n",
      "print(response.text)\n",
      "\n",
      "response = chat.send_message(\"How many paws are in my house?\")\n",
      "print(response.text)\n",
      "\n",
      "# You can also access the full conversation history\n",
      "for message in chat.get_history():\n",
      "    print(f'role - {message.role}: {message.parts[0].text}')\n",
      "```\n",
      "\n",
      "**6. Multimodal Inputs**\n",
      "The Gemini API supports multimodal inputs, allowing you to combine text with media files like images.\n",
      "\n",
      "```python\n",
      "from PIL import Image\n",
      "from google import genai\n",
      "\n",
      "client = genai.Client()\n",
      "\n",
      "# Assuming you have an image file named 'organ.png' in the same directory\n",
      "# image = Image.open(\"organ.png\")\n",
      "\n",
      "# For demonstration, let's assume 'image' is an Image object\n",
      "# You would load your actual image here.\n",
      "# Example: image = Image.open(\"/path/to/your/image.png\")\n",
      "# Since I cannot directly access local files, this part is illustrative.\n",
      "\n",
      "# If you had an image object loaded, you would use it like this:\n",
      "# response = client.models.generate_content(\n",
      "#     model=\"gemini-2.5-flash\",\n",
      "#     contents=[image, \"Tell me about this instrument\"]\n",
      "# )\n",
      "# print(response.text)\n",
      "```\n",
      "*(Note: To run the multimodal input example, you would need to have an image file and the `Pillow` library installed (`pip install Pillow`). The example above is illustrative as the current environment cannot access local files directly.)*\n",
      "\n",
      "**7. System Instructions and Configuration**\n",
      "You can guide the model's behavior with system instructions or override default generation parameters like `temperature` using a `GenerateContentConfig` object.\n",
      "\n",
      "```python\n",
      "from google import genai\n",
      "from google.genai import types\n",
      "\n",
      "client = genai.Client()\n",
      "\n",
      "# Example with system instruction\n",
      "response_with_instruction = client.models.generate_content(\n",
      "    model=\"gemini-2.5-flash\",\n",
      "    config=types.GenerateContentConfig(system_instruction=\"You are a polite assistant.\"),\n",
      "    contents=\"Hello there\"\n",
      ")\n",
      "print(\"Response with system instruction:\", response_with_instruction.text)\n",
      "\n",
      "# Example overriding temperature\n",
      "response_with_temp = client.models.generate_content(\n",
      "    model=\"gemini-2.5-flash\",\n",
      "    contents=[\"Explain quantum physics simply.\"],\n",
      "    config=types.GenerateContentConfig(temperature=0.1) # Lower temperature makes output less random\n",
      ")\n",
      "print(\"Response with specific temperature:\", response_with_temp.text)\n",
      "```\n",
      "\n",
      "This example demonstrates the core functionalities of the Gemini API for text generation, multi-turn conversations, and how to configure model behavior.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents='''Create a example on how to use Gemini? Using the docs \n",
    "https://ai.google.dev/gemini-api/docs/text-generation \n",
    "https://ai.google.dev/gemini-api/docs/quickstart''',\n",
    "    config={\"tools\": [{\"url_context\": {}}]},\n",
    ")\n",
    "\n",
    "# print the response\n",
    "print(f\"Response: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context used: https://ai.google.dev/gemini-api/docs/text-generation, https://ai.google.dev/gemini-api/docs/quickstart\n"
     ]
    }
   ],
   "source": [
    "# urls used for grounding\n",
    "print(f\"Context used: {', '.join([url.retrieved_url for url in response.candidates[0].url_context_metadata.url_metadata])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[GroundingSupport(\n",
       "    grounding_chunk_indices=[\n",
       "      0,\n",
       "    ],\n",
       "    segment=Segment(\n",
       "      end_index=300,\n",
       "      start_index=224,\n",
       "      text=\"\"\"Get an API Key**\n",
       "  You can obtain a free Gemini API key from Google AI Studio.\"\"\"\n",
       "    )\n",
       "  ),\n",
       "  GroundingSupport(\n",
       "    grounding_chunk_indices=[\n",
       "      0,\n",
       "    ],\n",
       "    segment=Segment(\n",
       "      end_index=536,\n",
       "      start_index=500,\n",
       "      text=\"It's recommended to set it this way.\"\n",
       "    )\n",
       "  ),\n",
       "  GroundingSupport(\n",
       "    grounding_chunk_indices=[\n",
       "      1,\n",
       "      0,\n",
       "    ],\n",
       "    segment=Segment(\n",
       "      end_index=670,\n",
       "      start_index=543,\n",
       "      text=\"\"\"Basic Text Generation**\n",
       "  Here's a basic example that generates text from a single text input using the `gemini-2.5-flash` model.\"\"\"\n",
       "    )\n",
       "  ),\n",
       "  GroundingSupport(\n",
       "    grounding_chunk_indices=[\n",
       "      1,\n",
       "    ],\n",
       "    segment=Segment(\n",
       "      end_index=1111,\n",
       "      start_index=968,\n",
       "      text=\"\"\"Multi-turn Conversations (Chat)**\n",
       "  The SDKs provide functionality to manage multi-turn conversations, keeping track of the conversation history.\"\"\"\n",
       "    )\n",
       "  ),\n",
       "  GroundingSupport(\n",
       "    grounding_chunk_indices=[\n",
       "      1,\n",
       "    ],\n",
       "    segment=Segment(\n",
       "      end_index=1672,\n",
       "      start_index=1551,\n",
       "      text=\"\"\"Multimodal Inputs**\n",
       "  The Gemini API supports multimodal inputs, allowing you to combine text with media files like images.\"\"\"\n",
       "    )\n",
       "  ),\n",
       "  GroundingSupport(\n",
       "    grounding_chunk_indices=[\n",
       "      1,\n",
       "    ],\n",
       "    segment=Segment(\n",
       "      end_index=2774,\n",
       "      start_index=2574,\n",
       "      text=\"\"\"System Instructions and Configuration**\n",
       "  You can guide the model's behavior with system instructions or override default generation parameters like `temperature` using a `GenerateContentConfig` object.\"\"\"\n",
       "    )\n",
       "  )]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# citations\n",
    "[response.candidates[0].grounding_metadata.grounding_supports]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine with Context URL with Google Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The latest version of FastAPI is 0.116.1, released on July 11, 2025. The latest version of Uvicorn is 0.35.0, released on June 28, 2025.\n",
      "\n",
      "Here is the `pip install` command with the latest versions:\n",
      "\n",
      "`pip install fastapi==0.116.1 uvicorn==0.35.0`\n",
      "Context used: https://gist.github.com/ultrafunkamsterdam/b1655b3f04893447c3802453e05ecb5e\n",
      "Website used: FastAPI support for React ( with working react-router ) Â· GitHub, pypi.org, sourceforge.net\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google import genai\n",
    "\n",
    "# create client\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\",\"xxx\"))\n",
    "\n",
    "# Generate a list of cookie recipes\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-preview-05-20\",\n",
    "    contents='find the latest versions of the libraries used here and create a pip install command. https://gist.github.com/ultrafunkamsterdam/b1655b3f04893447c3802453e05ecb5e',\n",
    "    config={\"tools\": [\n",
    "        {\"url_context\": {}},\n",
    "        {\"google_search\": {}},\n",
    "    ]},\n",
    ")\n",
    "\n",
    "# print the response\n",
    "print(f\"Response: {response.text}\")\n",
    "# urls used for grounding\n",
    "print(f\"Context used: {', '.join([url.retrieved_url for url in response.candidates[0].url_context_metadata.url_metadata])}\")\n",
    "# searched websited \n",
    "print(f\"Website used: {', '.join([site.web.title for site in response.candidates[0].grounding_metadata.grounding_chunks])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
