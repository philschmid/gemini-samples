{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Gemini Deep Research\n",
    "\n",
    "This notebook demonstrates how to use the new Gemini Deep Research agent via the Interactions API to perform complex research tasks, generate images based on the findings, and translate the results.\n",
    "\n",
    "**Preview:** The Gemini Deep Research Agent is currently in preview. The Deep Research agent is exclusively available using the [Interactions API](https://ai.google.dev/gemini-api/docs/interactions). You cannot access it through `generate_content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.14.0 environment at: /Users/philschmid/projects/personal/gemini-samples/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m24 packages\u001b[0m \u001b[2min 3.07s\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2mAudited \u001b[1m24 packages\u001b[0m \u001b[2min 0.29ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install google-genai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from google import genai\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Research Task (Polling)\n",
    "\n",
    "The following example shows how to start a research task in the background and poll for results. This is the standard way to interact with the Deep Research agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f1/3vdgcm01195b80qcp3t14n_m01b2f5/T/ipykernel_92393/2710857139.py:3: UserWarning: Interactions usage is experimental and may change in future versions.\n",
      "  interaction = client.interactions.create(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research started: v1_ChdWNHRmYVpUb0M0SDZ4czBQbV9LTTBBdxIXVjR0ZmFaVG9DNEg2eHMwUG1fS00wQXc\n",
      "............................"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# The Evolution of Google Tensor Processing Units: A Historical and Architectural Analysis\n",
       "\n",
       "### Key Points\n",
       "*   **Origins in Necessity:** The Tensor Processing Unit (TPU) project was initiated in 2013 when Google engineers realized that existing CPU and GPU infrastructure could not sustain the computational demands of ubiquitous voice search and deep learning applications without doubling datacenter footprints.\n",
       "*   **Architectural Paradigm Shift:** Unlike the Von Neumann architecture of CPUs, TPUs utilize a **systolic array** architecture. This design mimics the flow of blood through the heart, allowing data to flow through thousands of arithmetic logic units (ALUs) without accessing memory for intermediate results, drastically increasing efficiency for matrix multiplications.\n",
       "*   **Generational Evolution:** The lineage has evolved from the inference-only TPU v1 (2015) to the training-capable TPU v2 (2017) and v3 (2018), the optically-switched TPU v4 (2021), the specialized split of TPU v5e and v5p (2023), the high-performance Trillium (v6) (2024), and the inference-centric Ironwood (v7) (2025).\n",
       "*   **Software Co-Design:** The hardware evolution is inextricably linked to the development of the TensorFlow, JAX, and XLA (Accelerated Linear Algebra) software stack, enabling the hardware to be abstracted as a supercomputer rather than individual chips.\n",
       "*   **Edge Computing:** Parallel to datacenter accelerators, Google developed the Edge TPU and the Coral platform to bring machine learning inference to low-power, local devices, addressing latency and privacy concerns.\n",
       "\n",
       "### Introduction to Domain-Specific Architectures\n",
       "The trajectory of modern artificial intelligence is fundamentally constrained by the hardware upon which it runs. As Moore’s Law began to slow in the early 2010s, the general-purpose processor (CPU) could no longer deliver the year-over-year performance gains required by the exponential growth in neural network complexity. This necessitated a shift toward Domain-Specific Architectures (DSAs)—processors optimized for a specific class of workloads. Google’s TPU represents one of the industry's most significant commitments to DSA, specifically tailored for the tensor operations that underpin deep learning [cite: 1, 2].\n",
       "\n",
       "### The Systolic Array Advantage\n",
       "The defining characteristic of the TPU architecture is the systolic array. In a traditional CPU or GPU, values are repeatedly read from and written to registers or memory, consuming significant energy and time. In a systolic array, data flows from one processing unit to the next in a rhythmic fashion. The TPU v1, for instance, featured a 256x256 matrix of multiply-accumulate units (MACs). Weights are pre-loaded into the array, and activation data flows through it, performing massive matrix multiplications in a single clock cycle without intermediate memory access. This architecture allows TPUs to achieve orders of magnitude better performance-per-watt compared to general-purpose silicon [cite: 3, 4, 5].\n",
       "\n",
       "---\n",
       "\n",
       "## 1. Genesis: The Internal Crisis and TPU v1 (2013–2016)\n",
       "\n",
       "### 1.1 The Computational Cliff\n",
       "In 2013, Google’s internal projections indicated a looming infrastructure crisis. Calculations suggested that if every Android user utilized Google Voice Search for just three minutes a day, the company would need to double its entire datacenter capacity to handle the speech recognition workload [cite: 2, 6]. The computational intensity of deep neural networks (DNNs) and Large Language Models (LLMs) was incompatible with the existing fleet of CPUs and GPUs.\n",
       "\n",
       "### 1.2 Architecture of the First Generation\n",
       "The TPU v1, deployed internally in 2015 and announced publicly at Google I/O 2016, was an inference-only accelerator. It was designed not to train models, but to run them (inference) efficiently.\n",
       "*   **Process Node:** 28nm.\n",
       "*   **Clock Speed:** 700 MHz.\n",
       "*   **Compute Engine:** A 256x256 systolic array containing 65,536 8-bit integer multipliers.\n",
       "*   **Performance:** 92 TeraOPS (Trillion Operations Per Second).\n",
       "*   **Memory:** 28 MiB of on-chip software-managed memory; no High Bandwidth Memory (HBM).\n",
       "*   **Power:** ~40 Watts.\n",
       "\n",
       "The v1 was essentially a massive matrix multiplication engine driven by CISC (Complex Instruction Set Computer) instructions sent over a PCIe 3.0 bus from a host CPU. It excelled at the low-precision (8-bit integer) arithmetic sufficient for inference, delivering 15–30x higher performance and 30–80x higher performance-per-watt than contemporary CPUs and GPUs [cite: 5, 7, 8].\n",
       "\n",
       "### 1.3 Operational Impact\n",
       "TPU v1 was instrumental in several high-profile Google successes. It powered the AlphaGo system that defeated Lee Sedol in 2016. It was also deployed for Google Street View text processing, allowing the entire Street View database to be processed in less than five days, and was integrated into RankBrain for search result optimization [cite: 8, 9].\n",
       "\n",
       "## 2. The Training Era: TPU v2 and v3 (2017–2018)\n",
       "\n",
       "### 2.1 TPU v2: Enabling Training (2017)\n",
       "While v1 solved the inference bottleneck, the training of neural networks—which requires higher precision and backward propagation—remained a challenge. In 2017, Google introduced TPU v2, a fundamental redesign aimed at both training and inference.\n",
       "*   **Floating Point Support:** Unlike the integer-only v1, v2 introduced native support for **bfloat16** (Brain Floating Point), a format that retains the range of 32-bit floating point but with reduced precision, ideal for machine learning [cite: 8, 10].\n",
       "*   **HBM Integration:** To feed the hungry cores, v2 incorporated 16 GB of High Bandwidth Memory (HBM), providing 600 GB/s of bandwidth [cite: 7].\n",
       "*   **The TPU Pod:** This generation introduced the concept of the \"Pod,\" a supercomputer configuration. A v2 Pod connected 64 devices (256 chips) via a dedicated Inter-Chip Interconnect (ICI), creating a 2D torus topology capable of 11.5 PetaFLOPS [cite: 7].\n",
       "\n",
       "### 2.2 TPU v3: Liquid Cooling and Scaling (2018)\n",
       "Released in May 2018, TPU v3 pushed the thermal and performance envelopes.\n",
       "*   **Performance:** Each chip delivered ~123 TFLOPS (bf16), roughly double that of v2.\n",
       "*   **Thermal Management:** The increased power density necessitated the introduction of liquid cooling directly to the chip packages, a first for Google’s massive scale deployments [cite: 8, 11].\n",
       "*   **Memory:** HBM capacity doubled to 32 GB per chip (in some configurations) with 900 GB/s bandwidth [cite: 11].\n",
       "*   **Scale:** A TPU v3 Pod scaled to 1,024 chips, delivering over 100 PetaFLOPS of compute power. This generation solidified the TPU's role in training massive models like BERT and early Transformer iterations [cite: 10, 11].\n",
       "\n",
       "## 3. The Edge Frontier: Edge TPU and Coral (2018–2019)\n",
       "\n",
       "### 3.1 Bringing AI to the Edge\n",
       "Recognizing that not all inference can or should occur in the cloud due to latency and privacy constraints, Google unveiled the Edge TPU in July 2018.\n",
       "*   **Design Philosophy:** A miniature ASIC designed for \"inference at the edge\" within tight power and physical budgets.\n",
       "*   **Specifications:** Capable of 4 TOPS (Trillion Operations Per Second) using INT8 precision while consuming only 2 Watts of power [cite: 1, 12].\n",
       "*   **Coral Platform:** To democratize access, Google launched the Coral brand in 2019, offering development boards, USB accelerators, and System-on-Modules (SoMs) powered by the Edge TPU. This allowed developers to run TensorFlow Lite models locally on devices like Raspberry Pis [cite: 1, 13, 14].\n",
       "\n",
       "### 3.2 Integration in Consumer Hardware\n",
       "The Edge TPU architecture found its way into consumer devices, notably the Pixel Neural Core in the Pixel 4 and subsequent integrations in the Google Tensor SoC (System on Chip) used in Pixel 6 and later phones. These integrations power features like real-time photography processing, on-device translation, and voice typing [cite: 1, 15].\n",
       "\n",
       "## 4. Optical Networking and Exascale: TPU v4 (2021)\n",
       "\n",
       "### 4.1 The Interconnect Breakthrough\n",
       "Announced at Google I/O 2021, TPU v4 represented a paradigm shift in system-level architecture. The defining innovation was the integration of **Optical Circuit Switches (OCS)**.\n",
       "*   **3D Torus Topology:** Unlike the fixed 2D torus of previous generations, the OCS allowed TPU v4 pods to be dynamically reconfigured into various 3D torus topologies (e.g., 4x4x4 cubes). This flexibility allowed the system to route around failures and optimize topology for specific model parallelism strategies [cite: 10, 16].\n",
       "*   **Scale:** A single v4 Pod contained 4,096 chips, delivering 1.1 ExaFLOPS of peak compute—ten times the bandwidth per chip at scale compared to standard networking technologies [cite: 7, 16].\n",
       "\n",
       "### 4.2 Chip Specifications\n",
       "*   **Process:** Likely 7nm (based on contemporary timelines and density).\n",
       "*   **Compute:** ~275 TFLOPS (bf16) per chip.\n",
       "*   **Memory:** 32 GB of Unified HBM2 per chip with ~1,200 GB/s bandwidth [cite: 16, 17].\n",
       "*   **SparseCores:** TPU v4 introduced \"SparseCores,\" specialized dataflow units designed to accelerate embeddings—a critical component of recommendation models which often bottleneck on memory access rather than raw compute [cite: 10, 17].\n",
       "\n",
       "## 5. Divergence: TPU v5e and v5p (2023)\n",
       "\n",
       "In 2023, Google bifurcated its TPU lineup to address distinct market needs: cost-efficiency and maximum performance.\n",
       "\n",
       "### 5.1 TPU v5e: Efficiency First\n",
       "Launched in August 2023, the TPU v5e (Efficiency) was designed for medium-scale training and high-throughput inference.\n",
       "*   **Specs:** 197 TFLOPS (bf16) and 16 GB HBM2 per chip.\n",
       "*   **Value Proposition:** It offered 2x higher training performance per dollar and 2.5x inference performance per dollar compared to TPU v4. It supports pods of up to 256 chips [cite: 18, 19, 20].\n",
       "\n",
       "### 5.2 TPU v5p: Performance First\n",
       "Announced in December 2023, the TPU v5p (Performance) was the most powerful TPU to date, specifically engineered for training massive LLMs like Gemini.\n",
       "*   **Specs:** 459 TFLOPS (bf16) per chip.\n",
       "*   **Memory:** 95 GB of HBM2e with 2,765 GB/s bandwidth—3x the capacity of TPU v4.\n",
       "*   **Scale:** Scalable to 8,960 chips in a single pod using the high-speed OCS interconnect (4,800 Gbps/chip ICI) [cite: 21, 22].\n",
       "\n",
       "## 6. The Modern Era: Trillium (TPU v6) (2024)\n",
       "\n",
       "### 6.1 The Sixth Generation\n",
       "Unveiled in May 2024, Trillium (TPU v6) marked a return to a unified high-performance architecture, focusing on the immense demands of generative AI.\n",
       "*   **Performance Leap:** Google claimed a 4.7x increase in peak compute performance per chip compared to TPU v5e [cite: 23, 24].\n",
       "*   **Memory:** Doubled HBM capacity (32 GB) and bandwidth compared to v5e.\n",
       "*   **Energy Efficiency:** 67% more energy-efficient than v5e.\n",
       "*   **Matrix Multiply Unit (MXU):** The MXU size was expanded (likely back to 256x256 or larger effective throughput) and clock speeds were increased to achieve the performance gains [cite: 25].\n",
       "\n",
       "## 7. The Future: Ironwood (TPU v7) (2025)\n",
       "\n",
       "### 7.1 The Age of Inference\n",
       "By 2025, the focus of the AI industry began to shift from training massive foundation models to serving them (inference). Google’s 7th generation TPU, codenamed \"Ironwood,\" was unveiled in April 2025 to address this \"Age of Inference\" [cite: 7, 26].\n",
       "\n",
       "### 7.2 Architectural Specifications\n",
       "*   **Inference Focus:** While capable of training, Ironwood is optimized for high-volume, low-latency inference and \"thinking models\" (reasoning agents).\n",
       "*   **Performance:** A staggering 4.6 PFLOPS (FP8) per chip.\n",
       "*   **Memory:** 192 GB of HBM3e per chip with ~7.4 TB/s bandwidth. This massive memory capacity is critical for holding the Key-Value (KV) caches of trillion-parameter models [cite: 27, 28].\n",
       "*   **Scale:** Ironwood pods can scale to 9,216 chips, creating a single domain with 1.77 Petabytes of shared memory [cite: 26, 29].\n",
       "*   **Power Efficiency:** Ironwood claims 2x better performance-per-watt than Trillium [cite: 30].\n",
       "\n",
       "## 8. Comparative Specifications Table\n",
       "\n",
       "The following table summarizes the key specifications across the major TPU generations.\n",
       "\n",
       "| Feature | TPU v1 | TPU v2 | TPU v3 | TPU v4 | TPU v5e | TPU v5p | Trillium (v6) | Ironwood (v7) |\n",
       "| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n",
       "| **Year** | 2015 | 2017 | 2018 | 2021 | 2023 | 2023 | 2024 | 2025 |\n",
       "| **Primary Use** | Inference | Train/Infer | Train/Infer | Train/Infer | Efficiency | Performance | Train/Infer | Inference/Scale |\n",
       "| **Process** | 28nm | - | - | 7nm | - | - | - | 3nm/5nm (est) |\n",
       "| **Peak Perf** | 92 TOPS (INT8) | 45 TFLOPS | 123 TFLOPS | 275 TFLOPS | 197 TFLOPS | 459 TFLOPS | ~926 TFLOPS | 4,614 TFLOPS (FP8) |\n",
       "| **HBM/Chip** | N/A (SRAM) | 16 GB | 32 GB | 32 GB | 16 GB | 95 GB | 32 GB | 192 GB |\n",
       "| **HBM BW** | 34 GB/s (DDR3) | 600 GB/s | 900 GB/s | 1,200 GB/s | 819 GB/s | 2,765 GB/s | 1,600 GB/s | ~7,400 GB/s |\n",
       "| **Pod Size** | N/A | 256 chips | 1,024 chips | 4,096 chips | 256 chips | 8,960 chips | 256 chips | 9,216 chips |\n",
       "| **Interconnect**| PCIe 3.0 | 2D Torus | 2D Torus | 3D Torus (OCS)| 2D Torus | 3D Torus (OCS)| ICI | ICI (9.6 Tb/s) |\n",
       "\n",
       "*Note: Performance metrics often vary based on precision (INT8 vs BF16 vs FP8). v1 is INT8. v2-v6 are typically cited in BF16. v7 is cited in FP8.* [cite: 7, 16, 22, 27, 31].\n",
       "\n",
       "## 9. Software and Ecosystem\n",
       "\n",
       "### 9.1 The XLA Compiler\n",
       "The secret weapon of the TPU is not just the silicon, but the compiler. XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra that optimizes TensorFlow, JAX, and PyTorch computations. It \"fuses\" operations, reducing memory access requirements—a critical optimization for the TPU's systolic array architecture. This allows the hardware to be agnostic to the higher-level framework, provided the XLA graph is generated correctly [cite: 8, 10].\n",
       "\n",
       "### 9.2 JAX and Pathways\n",
       "As models grew, Google introduced **JAX**, a Python library for high-performance numerical computing, and **Pathways**, a new asynchronous distributed dataflow system. Pathways allows a single model to span tens of thousands of TPU chips, abstracting the complexity of the underlying hardware topology. This software stack was essential for training Gemini and PaLM models on TPU v4 and v5 pods [cite: 10].\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "The history of the Google TPU is a case study in the power of vertical integration. By controlling the entire stack—from the datacenter cooling systems and optical switches to the silicon architecture and high-level compiler—Google has managed to scale AI performance exponentially over a decade. From the humble beginnings of the TPU v1 saving Google from a datacenter crisis to the massive, liquid-cooled Ironwood superpods powering the age of generative AI, the TPU remains a cornerstone of the global AI infrastructure. As the industry moves toward trillion-parameter models and agentic AI, the TPU's architectural focus on interconnect bandwidth, memory capacity, and systolic efficiency positions it as a critical counterweight to the dominance of general-purpose GPUs.\n",
       "\n",
       "**Sources:**\n",
       "1. [viso.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH0OAYEEnuaXQmn79V_Dz_dZcOo9GqYmww5r1U0YPVdfgSm-zwkYlgIFM2rjZkEIAOhXpJ1ZsyZA24F2uubJz-1RDAEW8v4b8Zz058e90NAfI6o2hA7itnhvYf-)\n",
       "2. [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH9x0BVh44RHvDCEarkgDtoPOLsMAN_5yH0L204U40UZr22aMXbBr48eZVzknL75teP9DuYiPX5WYAXRL_KwgNqEI4Gq9VwNoRfmgGYL7Xcl7F5KycX8jP1TfMe71iiCTGMcdpRh-LkPXZYCSagK3aJCdds3axhBzxdxo3E3mgWs0tVwfSlCLG5iKf4X7cRqbhiKBn86c43gr6daZajM8FeGrWqR3We_oFu)\n",
       "3. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEOLD-euz7QEFzWD6hCbeJHnoBCsPSKTxbbiJV1pLv5DoXFpCyTdLdlv6cgF4mCrOLjCJH1bQ26LSzaAzSEAz0fL6TpSa3NVk7ZmjCiWx1mQf2cUGSG04ldxWMu044ksJD8cyZdYWZniKtMNeBJtsRYFa1RFD2T-Q==)\n",
       "4. [bytebytego.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHUHPBIjDwRremV5ujmmdzVARsy3CSlpcUGeTxqfXhpcRc0CErE-5Qu5RA-HcHdbjf-sldjQvW_fj0t0JYN-tU6mArVSzjhSrYtQ9XZIPGsvbdHk1P_QoCIGeLkFTGXaIcK-h_L3vcQNEDAtbuAvNebNO1mTw4F)\n",
       "5. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEEnT-MAG9sAe-0IUrl23v61OiUp8BzNAcv6lcQiO9YUHKurQWbievKi-aZ5D5IoiLB0NbKnJHswxqvPZjWAuD8ppizJM9uBrwnjI5LYZddpLHYOgHyOuncbipvZXk-Cdn83Q0EInQq0gSh_uW94yaBBZSI99KA2MIK6wnA1sEZcV9ciuIO_4xuCdGEKQ7ErNMPDyw-W6a7m_vYSIb_fsvyBo1-3ZgE3EqRQF11Ew==)\n",
       "6. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG-jS_UF0SZ_ghU3oKf9QTat-U4BExuNKdcijvm7gwUDmo-9JSpS7L6wylu4p_IpArXcgRnyCWlT9SAw4vIJvuOK9p6JjYt2zxiZeTIy1ozJKKz6aYx6ErqqUB1n_3CBFBSXheTYguZVhq_wKmKedZcF5izXhVwcZ5y3h5NrbtEPA==)\n",
       "7. [wikipedia.org](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFcgR6FysipTq0VVzYYHIS5-mvYzJu78exta1nrYToRMdG3jswyRrbz40L0IgzX6D1uzUYdK-F2o2M3oNwtnozRUURABKozN213AZxT-BsD6GFoJDL3UFZ2JBrthjlHmv5li4Zy-fTzjXyO)\n",
       "8. [introl.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGVyVl4KAeCzF-QjO8O8gArDDT6DVSIMNmMFYb_hVuWpZxUFGrTPYmigRB9TewS_YWSE_NFUzpQ5nV813vZtyMoy15gKJConRvqlExJvukdScstGJwhjVgEa_Q3-Ii8yOeqpLY2sHKpdyJwdD_RyjpAv8hVOF2IRUbxQYGsQbJy0heT)\n",
       "9. [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGSOXoIyZ6fR3D8Snd7blFdSa84cGo-PvTPknbVp8ZEGZrwAhimVrUjwy-WLURtIKxAXjd8Rs8K0r5o5VUGAtGWJwtS7i0vEEEO26Hip32UMaHCr5WfZ-jxFL4pKJrsxLkz3aDwj_9P8-3cMKLoaA4dAvU1DV8=)\n",
       "10. [intuitionlabs.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF8deIQ-I4IeBvGMMbsqwDtXr6_zg39XUNfVntknSQiGzEhO1a43tu24NlGjrOx7ZT_ewr8mWk3hM65bMvP346oafOVar1W4NGnZTFNHIcRTXI6xAz_a3FlCN-H_N_Z9kSKs1oJbx3XuIt8FiMmza_V6a79Q3e1sqg=)\n",
       "11. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFxc11tz916jwWFaOoVOv0NC0vpNTrZOdUxugAW1OA2YdPY9h_csaXKf4NpCjjtW4ytKevU-rWqXk44NVwrdlpyGJxcplBKy8UN6rrf7rmRzswZTOoR2RzGVRWqbFbCpg==)\n",
       "12. [wikichip.org](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEL5wDLUTAXuUNVTFe4koc9UZU_9GvZdXTSyE2eaq5X4mZUZo65lwRHDk0Pi5afnS7Q282Fq9NjgA7O2YUfsA423vUe4wMQ5mzNShtUeBd34Z_HSoKtEC5fLHGEBtmUvnugJiFZl54=)\n",
       "13. [thenewstack.io](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGhj0ujJwRgb4GcyipEbyQulu5to-KjegqI-JgWZ1teziymGcK1JmHUi9BhKKN90eilLPu84RTeKAm4fgmnqSSLMTRP-U0ANIlkO914kBnX0VHgeIGJrDHp0EEd-tRCpMRf92MVGRJ0Ix9Eo2PfPMzLFZu_wz0S-vqrRm2VY_upDbJdVyteJcmE65wdRp_ftZHCyA==)\n",
       "14. [abopen.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFbCwAXbizoEYqaXKT5z3YNi9c9GjoZrzGB0s6kqhpiPHd3u8Y6XYAHqpCA8QAYCOqIiXkpewN6rvvuneqOOthKMLrCBeyD0SHfuD_FJb06tk86DvTCo7KTXfl5HbuPQhRbQd6T8gztNN0sfg_s5p8k3ZZ7-QKzjRjUVR8DDymZrWsWoZKo8L9eJKCdFzm8zA==)\n",
       "15. [wikipedia.org](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFfDatVfjCwlSM47A3xh2h4mf2KlShEhQO16jvPqYmjsuJNnwHPJ_lRzoAMjPmN8_Okmjt7xoGUdjqUbc9cSnXAiTA845Q0eszH2gIURvL-xDwSIccTxHasPMV2XDDTv97W)\n",
       "16. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG867SFcAt0LhmNYyu5fOoUmXrZ-H0xKmuvsyJCl3mJvY_9WeOgLTQ1BiNGq32-kG0WrpQp5KE3Kzi5mRJMxnWaCYIK1VfJZSrvbGbcNP_hgYVOSUtQ8kxFTu7THpOvXg==)\n",
       "17. [elprocus.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGVJMEFhsK981JxmqAi6fqIrAWCXl_NmEmOAzgQUfbd8TZLvwsrnuvoUyVHoFAL55GbuG7DYXKTi8OuCi323iSx90seMhDzuwWrQ-OIgvSssGLZZ47boyR8AF7Z-Wg=)\n",
       "18. [convergedigest.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEFUdVSiz2gNWyg8C9iVXrj8hNR8OdPmuOw1NI-vDuRAs9C697Bvr0WkEmxLNPMsLAuw6Qi6B8-JZUJnHPYzTx23ixXCd-un2beJSO2pWSlEcJ3RJ_ph8G9xFgx_lQefzLoiZJzH1kek64aX8XMvVxI)\n",
       "19. [techpowerup.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFafvicYQJYhG8ZZxRpDHueAE19T3qsTjaAUMCcXEWvSf7w4Hf265tYt9wn_c7D4CopWnnhK7z6jJXcy9p_P1tc_KxQDyvkNbhfTxnEmL_KXKpY_XGgp7Mc1A47d7jvx-rfbzCnksn-Cu3RG5ij85IrL1Gbf0eU0b11p3ikgJqAH399Ysi-yHoQRCBz3YJTweVg16Ioi2J4EVhdNc-Q8to=)\n",
       "20. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGHmwdJ3hBR7Xo5WS5_tVXoP2OWjP7m42EZukbTs80EhA-drwj3A4FeCbdaKwzT_ohACDmrEB7Y_JTI_SN8jatyKO-wn2LxBT7XqCDdX3gVPdsRs9zeUZC6MyoMVVo8JT8=)\n",
       "21. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFKUSL9rcddf1Fbl3f7VqNE0LwVI9Fonl5FBV0z-ydISBKLss4zPvLuo-kqmToo4dKxAunETUB691VSueXJB4JKN7jpbvDNGUQ6CJrXSGC2Fj-HbUixtYkuVxsLqIsREcowixVdIAOcIhZHrmpGq-1wjctNojr1NYfXerxMl9ibpn-ujtV7ZyuYCui0OWPJFFHfKYFup98RdJCjcUWOyis=)\n",
       "22. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH4p0-bN9GW8fObnyv5L4Uzf22UeU0XojqoHeunSzZ7cxAc2-xeJtfHjn0aJRmkOZOJs8SnqqVMZHBadCa5FHwGlBM64G7KghzCpV4McWZNjVMR-s2R8hQ3ECFVkJEdig0=)\n",
       "23. [itdaily.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHrx3Bho17HqV0yf5LrFTSHqKgA36qWzAkZzyMwMr4_frOCcuiZKK_hMZiQnkncbA-T00aZmmELkkieAczALm8tTKuGHrUqKI7zgCFIuRiO62AbKhSGbHUeC1ei97UECkXiKg4A1xL78U0tqss=)\n",
       "24. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGJWrlWcfCtFowtJ2xiIoVzDTc6-ZuQwBiD5lpAfn3h0qrXEHI0116vHw-iok_CU1lpg3A-RE28jRfa6ufFUitOTF7DUJkYfPwLrgcLJrjjq3FUM5JBSb_SSfb5lBR2u0UCD-aLeVstH6nIihni4fZYgd87pn5kXiSc6e8j37j753CPdGiLXEuN3-ssNdRbPNQ=)\n",
       "25. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE-iXXfjszKIeC0jDRj5_Hqgl_yTLkRBYpZsQZGo1KmYjdvOChEFa9mFg3263TIW_rP6_jisJ8VqrgufvUkCXOYEXLrri9JGjq6OojRWm03iLHW7minig1wFAyWp7FwWzJNdoo7Os6aUJJevvaCN28erxEy8sRHwMpHrZ8084D0QSDw8WhozQ==)\n",
       "26. [yolegroup.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGMxtb60-ssqMq1zO_tsIXDgoonTb2xLd1OxWjGh6bJhiILWhaFT9OXIwAASOToh-94spAZMEZiIshhu9wgFZ7S__kpVi3r7iVyLO6mq5IaK4WHJtnxb3-Lk52k9sVSwvu726GUuE1oyer6nv-7Ivk8EiqANfFEdkKqLf-tAM_YknRaoWHSnxbVSamqPg-XnzI=)\n",
       "27. [financialcontent.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHFh4M4A1GnB_KCAQ707Aj8s2oeqHhyysu6EtQsBqXaBdLC2CvKOR0xmzFFOi8y2HAsxtbLNmMNA1iE3W82M4Vw1X5Hk1XCk2RcLpVriJqsrZm-t13Ob8JTLXcAhLa-65HBu3FBq3J690kHzJy_oAMvA2cDwHceeyEfWRZjmDnw3jHW1FQgutGycUDDTAJ6zdjhovfBFSQu6aVoB0B-U4Dai7UGRLVz2AwSL_hZA_L0uFaBMXS5EYQXVtZTUYBcDttgjHZWJINYCKff8STy)\n",
       "28. [ctol.digital](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGRraf0jX2CQ74ip15S7NXiDm8SBvxxLdSU12IXrQj9YzDF0Fg3JCjgXi3TljfAjaW2-3nALSPsfRMamLvh__9-ULlzIBPHDLrHFM0QQ0RaSHPI0UQNf6_Goshmue5dPOXNggGZj2kezLBOu9bLNwEiqBPpYV3QzVAkVaEZNZitBjFlkwVkJxR0ka21VuzpRWRZ9FrMd2t0UbNXyZCVr88ezlRwplSfqqK19w==)\n",
       "29. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG7sWDmrlpKfXGzLdtN7j5UYtwrJmE5lmVZp416gEXatJK9J8scLKoTJmQuHqyWP0BnbxCErmYbV46XgE28Ag18B9s9LuYM76rvWm_jAfrZ3fcKvlD3C-6vvs4lU_cbthH9bPryCG25t6QMjOwnpZNr9-DzBZdpThoqtAQefDUOK__WZEs5WMFOrEom0XvVBA_4_KH4S8b62wbCR-NJcCpd)\n",
       "30. [insidehpc.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGKraV-gdGWA6YJ_UTU4QPGX0WMMLE7QcFoRiQFpL2hslK7kHR3aAOUBArFihnEQHFQGT4UZEFA1T7bpj5ctOHadpFHnelTl5Ii2CAnGnCnpGvYZDAGwF6Dk3DAFoS5LTsPAX4L5OgcfHj0mmfA3Jpg3UkRaJu2qIwa)\n",
       "31. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEPa7JhUmgiWKhLinGLI7EsFnboXODO8E2mk-G07Z96UHQsIcPBYAiGlK6_BE5z5TafxiZ47Erb0j3M0r9JAKzrVd_Qn261ynbVpOxJCTwRk6npN0zBuoDzIKmAu5EIdew=)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"Research the history of Google TPUs.\"\n",
    "\n",
    "interaction = client.interactions.create(\n",
    "    agent='deep-research-pro-preview-12-2025',\n",
    "    input=prompt,\n",
    "    background=True\n",
    ")\n",
    "\n",
    "print(f\"Research started: {interaction.id}\")\n",
    "# Poll for results\n",
    "while True:\n",
    "    interaction = client.interactions.get(interaction.id)\n",
    "    if interaction.status == \"completed\":\n",
    "        break\n",
    "    elif interaction.status == \"failed\":\n",
    "        print(f\"Research failed: {interaction.error}\")\n",
    "        break\n",
    "    \n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    time.sleep(10)\n",
    "\n",
    "display(Markdown(interaction.outputs[-1].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Advanced Research Task (Streaming, Thinking, Promoting)\n",
    "\n",
    "Deep Research supports streaming to receive real-time updates on the research progress (`thinking_summaries`). You can steer the agent's output by providing specific promting instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction started: v1_ChdpWXhmYWFpX0UtV1d2ZElQOGU3WTBBNBIXaVl4ZmFhaV9FLVdXdmRJUDhlN1kwQTQ\n",
      "**Establishing Research Context**\n",
      "\n",
      "I'm initiating the research process to build a strategic briefing document on Google TPUs for a developer audience. Given the current date is January 2026, I must focus heavily on recent developments from 2025 and late 2024, as well as forward-looking plans for 2026 and beyond. This requires synthesizing information across history, recent technological breakthroughs, competitor landscape, and future roadmaps.\n",
      "\n",
      "\n",
      "\n",
      "**Initial Research Plan**\n",
      "\n",
      "My immediate plan is to conduct broad searches to establish the current status of Google's TPU technology, focusing on the recent releases like TPU v5p and the rumored next generation, Trillium (v6). I will also start gathering competitive intelligence on major players like NVIDIA and AMD to understand their product timelines relative to the 2026 market.\n",
      "\n",
      "\n",
      "\n",
      "**Unveiling TPU Generations**\n",
      "\n",
      "I've successfully synthesized a detailed timeline of Google's Tensor Processing Units. The core focus is on the recent v6 (Trillium, generally available late 2024 with 4.7x performance improvement over v5e) and the highly anticipated v7 (Ironwood), unveiled in 2025. It's clear that v7 is heavily geared toward high-scale inference, marking a strategic shift in capabilities.\n",
      "\n",
      "\n",
      "\n",
      "**Emerging Data Conflicts**\n",
      "\n",
      "While gathering specifications for TPU v7 'Ironwood,' I've encountered conflicting details, which I need to resolve. Specifically, sources differ on the launch date (April 2025 vs. November 2025) and the type of memory used (HBM3e vs. HBM4). This memory specification is critical for determining the true performance profile of the new generation.\n",
      "\n",
      "\n",
      "\n",
      "**Competitive Landscape Refined**\n",
      "\n",
      "I have also gathered substantial information on key competitors. NVIDIA's next-generation Rubin (R100) is slated for mass production in late 2025/early 2026, directly competing with v7. Additionally, the AMD Instinct MI350/MI400 series provides a clear roadmap through 2027. I also noted a major software breakthrough with the vLLM TPU plugin, which is a significant move to facilitate easier migration of PyTorch workloads to TPUs.\n",
      "\n",
      "\n",
      "\n",
      "**Next Research Focus**\n",
      "\n",
      "My next actions will be highly targeted to resolve the remaining ambiguity. I need to perform specific searches to confirm the precise memory type and TFLOPS specification for the TPU v7 'Ironwood.' I also need to verify the exact timelines for NVIDIA's Rubin and AMD's MI400 to build an accurate comparative table for the user. Finally, I will seek further details regarding developer enablement, specifically confirming the impact and usage of the vLLM TPU plugin.\n",
      "\n",
      "\n",
      "\n",
      "**Synthesizing Recent TPU Developments**\n",
      "\n",
      "I have successfully synthesized a significant amount of information regarding Google's current and next-generation TPUs, primarily focusing on the v5p and the recently launched TPU v6, codenamed Trillium. I've noted that the major architectural focus for Trillium is on increasing the number of chips per pod (256 TPUs) and enhancing networking capabilities (3D toroidal mesh) to support exascale computing for large language models. The v5p, which was the incumbent in late 2024, is noted for its efficiency and scaling, acting as the bridge to the latest technology.\n",
      "\n",
      "\n",
      "\n",
      "**Clarifying Future Roadmap Projections**\n",
      "\n",
      "A key finding from my investigation into the competitive landscape, specifically looking at NVIDIA's Rubin (2026) and AMD's MI400 (2026/2027), has helped solidify the likely trajectory of the Google TPU roadmap. I found a reference to a '7th-Gen TPU with HBM4' being projected for 2026. This strongly suggests that a potential high-end refresh or 'Ultra' variant of the current generation, likely to be codenamed 'Ironwood' (v7), will emerge in late 2026 to directly compete on memory bandwidth with NVIDIA's upcoming HBM4 adoption. This insight allows me to frame the Google roadmap not just as sequential generations, but as rapid iterative releases tailored to the fierce HBM competition.\n",
      "\n",
      "\n",
      "\n",
      "**Preparing for Final Structure**\n",
      "\n",
      "I have collected sufficient information to populate the core sections of the strategic briefing document, covering the technical details of the recent TPU generations (v5p, Trillium v6), the architectural innovations, and the competitive comparison with NVIDIA's Rubin and AMD's MI300/MI400 series. While the user asked for the top three competitors, I have enough detail on NVIDIA and AMD for a robust comparison table, and I will include AWS Trainium in the narrative text as a significant competitor, particularly regarding pricing and cloud infrastructure offerings. I am now transitioning to the final phase of synthesis, preparing to structure and present the final briefing document.\n",
      "\n",
      "**Verifying Key TPU Information**\n",
      "\n",
      "I am beginning the research to verify the core claims regarding Google's Tensor Processing Units (TPUs). Specifically, I need to confirm the status and technical details of the recently mentioned TPU v6 (Trillium) and the projected TPU v7 (Ironwood), along with their launch timelines. The candidate briefing mentioned significant events in late 2025 (which falls within the 'last 12 months' window), so validating these facts is my primary focus.\n",
      "\n",
      "\n",
      "\n",
      "**Addressing Competitive Landscape and Future Goals**\n",
      "\n",
      "To provide a complete strategic briefing, I am also focusing on confirming the roadmap for Google's major competitors, particularly the rumored timelines for NVIDIA's Rubin R100 and AMD's Instinct MI350/MI400 series. Additionally, I need to substantiate two major forward-looking claims: Google's ambitious '5 Million TPU' goal by 2027 and the reported deal with Anthropic for 1 million TPUs. These future projections are crucial for the 2026 and beyond section of the briefing.\n",
      "\n",
      "\n",
      "\n",
      "**Next Steps: Detailed Web Inquiry**\n",
      "\n",
      "I have formulated a set of detailed inquiries to simultaneously investigate the Google TPU roadmap, the competitor timelines, and the large-scale deployment goals, including checking for recent software developments like the TPU vLLM plugin and PyTorch support. This broad initial search will help me gather the necessary foundational data to construct the comparison table and the strategic narrative.\n",
      "\n",
      "\n",
      "\n",
      "**Synthesizing Recent TPU Developments**\n",
      "\n",
      "I have successfully gathered substantial and current details regarding Google's TPU lineup, particularly the TPU v6 'Trillium' and the recently released TPU v7 'Ironwood'. The information confirms the general availability of 'Ironwood' aligns with the simulated timeframe of early 2026. Key specifications like 4,614 TFLOPs (FP8) and 192GB HBM3e are now backed by multiple search snippets, increasing my confidence in the data.\n",
      "\n",
      "\n",
      "\n",
      "**Verifying Competitor Roadmaps**\n",
      "\n",
      "My investigation into competitors, specifically NVIDIA and AMD, has yielded matching timelines. I found confirmation that NVIDIA's Rubin (R100), the successor to Blackwell, is expected to transition to mass production in late 2025/early 2026. Similarly, AMD's Instinct MI350 launch in mid-2025 and the MI400 anticipated in 2026 are also corroborated, allowing me to fully map the competitive landscape as of January 2026.\n",
      "\n",
      "\n",
      "\n",
      "**High-Profile Customer Commitments**\n",
      "\n",
      "A significant new insight is the scale of customer commitment, evidenced by a search result mentioning Anthropic signing a massive deal for 'up to one million TPUs'. This confirms the colossal scale of Google's AI infrastructure expansion and the strong market uptake of the latest generation hardware and the associated software improvements, like the vLLM TPU plugin unified backend announced in October 2025.\n",
      "\n",
      "\n",
      "\n",
      "**Targeting Final Data Gaps**\n",
      "\n",
      "Although the overall briefing is well-supported, I am missing explicit, direct confirmation of two specific figures mentioned in potential responses: the '5 million TPUs by 2027' goal and the '1.77 PB shared memory' for the TPU v7 pod. To ensure the highest level of precision and fully resolve these quantitative details, I will perform one final, targeted search to secure direct sources for these numbers.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a complex prompt with formatting instructions\n",
    "prompt = \"\"\"\n",
    "Research the history and future developments of the Google TPUs.\n",
    "\n",
    "Focus on:\n",
    "1.  Key technological breakthroughs in the last 12 months.\n",
    "2.  Major competitors and their projected timelines for mass production.\n",
    "3.  Future developments and plans for 2026 and beyond\n",
    "\n",
    "Format the output:\n",
    "- as a strategic briefing document for an developer educating themselves about the Google TPU landscape.\n",
    "- Include a table comparing the top 3 leading companies.\n",
    "- Use short concise sentence and bullet points.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "stream = client.interactions.create(\n",
    "    agent=\"deep-research-pro-preview-12-2025\",\n",
    "    input=prompt,\n",
    "    background=True,\n",
    "    stream=True,\n",
    "    agent_config={\n",
    "        \"type\": \"deep-research\",\n",
    "        \"thinking_summaries\": \"auto\"\n",
    "    }\n",
    ")\n",
    "\n",
    "interaction_id = None\n",
    "last_event_id = None\n",
    "report = \"\"\n",
    "\n",
    "for chunk in stream:\n",
    "    if chunk.event_type == \"interaction.start\":\n",
    "        interaction_id = chunk.interaction.id\n",
    "        print(f\"Interaction started: {interaction_id}\")\n",
    "\n",
    "    if chunk.event_id:\n",
    "        last_event_id = chunk.event_id\n",
    "\n",
    "    if chunk.event_type == \"content.delta\":\n",
    "        if chunk.delta.type == \"text\":\n",
    "            report += chunk.delta.text\n",
    "        elif chunk.delta.type == \"thought_summary\":\n",
    "            print(f\"{chunk.delta.content.text}\\n\", flush=True)\n",
    "\n",
    "    elif chunk.event_type == \"interaction.complete\":\n",
    "        print(\"\\nResearch Complete\")\n",
    "        \n",
    "display(Markdown(report))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c9efa4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Combine Deep Research Interaciton with Model Interactions\n",
    "\n",
    "The Interactions API supports stateful interactions, which allows you to continue the conversation after the agent returns the final report by using the `previous_interaction_id`. \n",
    "\n",
    "You can continue the conversation after the agent returns the final report using a model to visualize the results using Nano Banana Pro or translate the results using Gemini Flash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating image...\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Precondition check failed.', 'code': 'invalid_request'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbase64\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating image...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m image_interaction = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43minteractions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-3-pro-image-preview\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mVisluaize the report ino a timeline slide.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprevious_interaction_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43minteraction_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_modalities\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mIMAGE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m image_data = [data \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m image_interaction.outputs \u001b[38;5;28;01mif\u001b[39;00m data.type == \u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m image_interaction.outputs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/personal/gemini-samples/.venv/lib/python3.14/site-packages/google/genai/_interactions/_utils/_utils.py:298\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    296\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    297\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/personal/gemini-samples/.venv/lib/python3.14/site-packages/google/genai/_interactions/resources/interactions.py:416\u001b[39m, in \u001b[36mInteractionsResource.create\u001b[39m\u001b[34m(self, input, model, api_version, background, generation_config, previous_interaction_id, response_format, response_mime_type, response_modalities, store, stream, system_instruction, tools, agent, agent_config, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m agent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m omit \u001b[38;5;129;01mand\u001b[39;00m generation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m omit:\n\u001b[32m    415\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInvalid request: specified `agent` and `generation_config`. If specifying `agent`, use `agent_config`.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_build_maybe_vertex_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_version\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minteractions\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgeneration_config\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprevious_interaction_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_interaction_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_mime_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_mime_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_modalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_modalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem_instruction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_instruction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43magent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43magent_config\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43minteraction_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateModelInteractionParamsStreaming\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minteraction_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateModelInteractionParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mInteraction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mInteractionSSEEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/personal/gemini-samples/.venv/lib/python3.14/site-packages/google/genai/_interactions/_base_client.py:1266\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1254\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1261\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1262\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1263\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1264\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1265\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1266\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/personal/gemini-samples/.venv/lib/python3.14/site-packages/google/genai/_interactions/_base_client.py:1068\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1065\u001b[39m             err.response.read()\n\u001b[32m   1067\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1068\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1070\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1072\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': 'Precondition check failed.', 'code': 'invalid_request'}}"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "print(\"Generating image...\")\n",
    "image_interaction = client.interactions.create(\n",
    "    model=\"gemini-3-pro-image-preview\",\n",
    "    input=\"Visluaize the report ino a timeline slide.\",\n",
    "    previous_interaction_id=interaction_id,\n",
    "    response_modalities=[\"IMAGE\"]\n",
    ")\n",
    "\n",
    "image_data = [data for data in image_interaction.outputs if data.type == \"image\"]\n",
    "\n",
    "for output in image_interaction.outputs:\n",
    "    image_data = base64.b64decode(output.data)\n",
    "    display(Image(data=image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "print(\"Translating...\")\n",
    "translate_interaction = client.interactions.create(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    input=\"Translate the report into simple German.\",\n",
    "    previous_interaction_id=interaction_id,\n",
    ")\n",
    "\n",
    "display(Markdown(translated_report.outputs[-1].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013bb6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
